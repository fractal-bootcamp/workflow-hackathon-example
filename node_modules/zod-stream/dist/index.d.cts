import OpenAI from 'openai';
import { z } from 'zod';
import { JsonSchema7Type } from 'zod-to-json-schema';

declare const MODE: {
    readonly FUNCTIONS: "FUNCTIONS";
    readonly TOOLS: "TOOLS";
    readonly JSON: "JSON";
    readonly MD_JSON: "MD_JSON";
    readonly JSON_SCHEMA: "JSON_SCHEMA";
};

type ActivePath = (string | number | undefined)[];
type CompletedPaths = ActivePath[];
type CompletionMeta = {
    _activePath: ActivePath;
    _completedPaths: CompletedPaths;
    _isValid: boolean;
};
type LogLevel = "debug" | "info" | "warn" | "error";
type ClientConfig = {
    debug?: boolean;
};
type ParseParams = {
    name: string;
    description?: string;
} & JsonSchema7Type;
type Mode = keyof typeof MODE;
type ResponseModel<T extends z.AnyZodObject> = {
    schema: T;
    name: string;
    description?: string;
};
type ZodStreamCompletionParams<T extends z.AnyZodObject> = {
    response_model: {
        schema: T;
    };
    data?: Record<string, unknown>;
    completionPromise: (data?: Record<string, unknown>) => Promise<ReadableStream<Uint8Array>>;
};
type InferStreamType<T extends OpenAI.ChatCompletionCreateParams> = T extends {
    stream: true;
} ? OpenAI.ChatCompletionCreateParamsStreaming : OpenAI.ChatCompletionCreateParamsNonStreaming;
type FunctionParamsReturnType<T extends OpenAI.ChatCompletionCreateParams> = T & {
    function_call: OpenAI.ChatCompletionFunctionCallOption;
    functions: OpenAI.FunctionDefinition[];
};
type ToolFunctionParamsReturnType<T extends OpenAI.ChatCompletionCreateParams> = T & {
    tool_choice: OpenAI.ChatCompletionToolChoiceOption;
    tools: OpenAI.ChatCompletionTool[];
};
type MessageBasedParamsReturnType<T extends OpenAI.ChatCompletionCreateParams> = T;
type JsonModeParamsReturnType<T extends OpenAI.ChatCompletionCreateParams> = T & {
    response_format: {
        type: "json_object";
    };
    messages: OpenAI.ChatCompletionMessageParam[];
};
type JsonSchemaParamsReturnType<T extends Omit<OpenAI.ChatCompletionCreateParams, "response_format">> = T & {
    response_format: {
        type: "json_object";
        schema: JsonSchema7Type;
    };
    messages: OpenAI.ChatCompletionMessageParam[];
};
type ModeParamsReturnType<T extends OpenAI.ChatCompletionCreateParams, M extends Mode> = M extends typeof MODE.FUNCTIONS ? FunctionParamsReturnType<T> : M extends typeof MODE.TOOLS ? ToolFunctionParamsReturnType<T> : M extends typeof MODE.JSON ? JsonModeParamsReturnType<T> : M extends typeof MODE.JSON_SCHEMA ? JsonSchemaParamsReturnType<T> : M extends typeof MODE.MD_JSON ? MessageBasedParamsReturnType<T> : MessageBasedParamsReturnType<T>;

declare class ZodStream {
    readonly debug: boolean;
    constructor({ debug }?: ClientConfig);
    private log;
    private chatCompletionStream;
    getSchemaStub({ schema, defaultData }: {
        schema: z.AnyZodObject;
        defaultData?: Partial<z.infer<typeof schema>>;
    }): Partial<z.infer<typeof schema>>;
    create<P extends ZodStreamCompletionParams<z.AnyZodObject>>(params: P): Promise<AsyncGenerator<Partial<z.infer<P["response_model"]["schema"]>> & {
        _meta: CompletionMeta;
    }, void, unknown>>;
}

declare function withResponseModel<T extends z.AnyZodObject, M extends Mode, P extends OpenAI.ChatCompletionCreateParams>({ response_model: { name, schema, description }, mode, params }: {
    response_model: ResponseModel<T>;
    mode: M;
    params: P;
}): ModeParamsReturnType<P, M>;

/**
 * `OAIResponseFnArgsParser` parses a JSON string and extracts the function call arguments.
 *
 * @param {string} data - The JSON string to parse.
 * @returns {string} - The extracted function arguments.
 *
 */
declare function OAIResponseFnArgsParser(data: string | OpenAI.Chat.Completions.ChatCompletionChunk | OpenAI.Chat.Completions.ChatCompletion): string;
/**
 * `OAIResponseToolArgsParser` parses a JSON string and extracts the tool call arguments.
 *
 * @param {string} data - The JSON string to parse.
 * @returns {Objstringect} - The extracted tool call arguments.
 *
 */
declare function OAIResponseToolArgsParser(data: string | OpenAI.Chat.Completions.ChatCompletionChunk | OpenAI.Chat.Completions.ChatCompletion): string;
/**
 * `OAIResponseJSONParser` parses a JSON string and extracts the JSON content.
 *
 * @param {string} data - The JSON string to parse.
 * @returns {string} - The extracted JSON content.
 *
 *
 */
declare function OAIResponseJSONParser(data: string | OpenAI.Chat.Completions.ChatCompletionChunk | OpenAI.Chat.Completions.ChatCompletion): string;
/**
 * `OAIResponseParser` parses a JSON string or a response object.
 * It checks if the input contains function call arguments. If it does,
 * it uses `OAIResponseFnArgsParser` to parse the input, otherwise, it uses `OAIResponseTextParser`.
 *
 * @param {string | Stream<OpenAI.Chat.Completions.ChatCompletionChunk> | OpenAI.Chat.Completions.ChatCompletion} data - The input to parse.
 * @returns {string} - The result of the appropriate parser.
 */
declare function OAIResponseParser(data: string | OpenAI.Chat.Completions.ChatCompletionChunk | OpenAI.Chat.Completions.ChatCompletion): string;

interface OaiStreamArgs {
    res: AsyncIterable<OpenAI.ChatCompletionChunk>;
}
/**
 * `OaiStream` creates a ReadableStream that parses the SSE response from OAI
 * and returns a parsed string from the response.
 *
 * @param {OaiStreamArgs} args - The arguments for the function.
 * @returns {ReadableStream<string>} - The created ReadableStream.
 */
declare function OAIStream({ res }: OaiStreamArgs): ReadableStream<Uint8Array>;
/**
 * `readableStreamToAsyncGenerator` converts a ReadableStream to an AsyncGenerator.
 *
 * @param {ReadableStream<Uint8Array>} stream - The ReadableStream to convert.
 * @returns {AsyncGenerator<unknown>} - The converted AsyncGenerator.
 */
declare function readableStreamToAsyncGenerator(stream: ReadableStream<Uint8Array>): AsyncGenerator<unknown>;

type CreateAgentParams = {
    defaultClientOptions: Partial<OpenAI.ChatCompletionCreateParams> & {
        model: OpenAI.ChatCompletionCreateParams["model"];
        messages: OpenAI.ChatCompletionMessageParam[];
    };
    /**
     * Mode to use
     * @default "TOOLS"
     *
     * @type {Mode}
     * */
    mode?: Mode;
    /**
     * OpenAI client instance
     * @default new OpenAI()
     *
     * @type {OpenAI}
     * */
    client?: OpenAI;
    response_model: {
        schema: z.AnyZodObject;
        name: string;
    };
};
type AgentInstance = ReturnType<typeof createAgent>;
type ConfigOverride = Partial<OpenAI.ChatCompletionCreateParams>;
/**
 * Create a pre-configured "agent" that can be used to generate completions
 * Messages that are passed at initialization will be pre-pended to all completions
 * all other configuration can be overriden in the completion call.
 *
 * @param {CreateAgentParams} params
 *
 * @returns {AgentInstance}
 */
declare function createAgent({ defaultClientOptions, response_model, mode, client }: CreateAgentParams): {
    /**
     * Generate a single stream completion
     * @param {ConfigOverride}
     *
     * @returns {Promise<ReadableStream<Uint8Array>> }
     */
    completionStream: (configOverride: ConfigOverride) => Promise<ReadableStream<Uint8Array>>;
    /**
     * Generate a standard completion
     * @param {ConfigOverride}
     *
     * @returns {Promise<z.infer<typeof response_model.schema>> }
     */
    completion: (configOverride: ConfigOverride) => Promise<z.infer<typeof response_model.schema>>;
};

declare function isPathComplete(activePath: ActivePath, data: {
    _meta: CompletionMeta;
}): boolean;

export { type ActivePath, type AgentInstance, type ClientConfig, type CompletedPaths, type CompletionMeta, type ConfigOverride, type CreateAgentParams, type FunctionParamsReturnType, type InferStreamType, type JsonModeParamsReturnType, type JsonSchemaParamsReturnType, type LogLevel, MODE, type MessageBasedParamsReturnType, type Mode, type ModeParamsReturnType, OAIResponseFnArgsParser, OAIResponseJSONParser, OAIResponseParser, OAIResponseToolArgsParser, OAIStream, type ParseParams, type ResponseModel, type ToolFunctionParamsReturnType, type ZodStreamCompletionParams, createAgent, ZodStream as default, isPathComplete, readableStreamToAsyncGenerator, withResponseModel };
