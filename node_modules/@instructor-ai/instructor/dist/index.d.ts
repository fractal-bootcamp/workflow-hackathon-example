import OpenAI from 'openai';
import { Stream } from 'openai/streaming';
import { z } from 'zod';
import { CompletionMeta as CompletionMeta$1, Mode as Mode$1, ResponseModel as ResponseModel$1 } from 'zod-stream';

type GenericCreateParams<M = unknown> = Omit<Partial<OpenAI.ChatCompletionCreateParams>, "model" | "messages"> & {
    model: string;
    messages: M[];
    stream?: boolean;
    max_tokens?: number | null;
    [key: string]: unknown;
};
type GenericRequestOptions = Partial<OpenAI.RequestOptions> & {
    [key: string]: unknown;
};
type GenericChatCompletion<T = unknown> = Partial<OpenAI.Chat.Completions.ChatCompletion> & {
    [key: string]: unknown;
    choices?: T;
};
type GenericChatCompletionStream<T = unknown> = AsyncIterable<Partial<OpenAI.Chat.Completions.ChatCompletionChunk> & {
    [key: string]: unknown;
    choices?: T;
}>;
type GenericClient = {
    [key: string]: unknown;
    baseURL?: string;
    chat?: {
        completions?: {
            create?: <P extends GenericCreateParams>(params: P) => Promise<unknown>;
        };
    };
};
type ClientTypeChatCompletionParams<C> = C extends OpenAI ? OpenAI.ChatCompletionCreateParams : GenericCreateParams;
type ClientTypeChatCompletionRequestOptions<C> = C extends OpenAI ? OpenAI.RequestOptions : GenericRequestOptions;
type ClientType<C> = C extends OpenAI ? "openai" : C extends GenericClient ? "generic" : never;
type OpenAILikeClient<C> = OpenAI | (C & GenericClient);
type SupportedInstructorClient = GenericClient | OpenAI;
type LogLevel = "debug" | "info" | "warn" | "error";
type CompletionMeta = Partial<CompletionMeta$1> & {
    usage?: OpenAI.CompletionUsage;
};
type Mode = Mode$1;
type ResponseModel<T extends z.AnyZodObject> = ResponseModel$1<T>;
interface InstructorConfig<C> {
    client: C;
    mode: Mode;
    debug?: boolean;
    logger?: <T extends unknown[]>(level: LogLevel, ...args: T) => void;
    retryAllErrors?: boolean;
}
type InstructorChatCompletionParams<T extends z.AnyZodObject> = {
    response_model: ResponseModel<T>;
    max_retries?: number;
};
type ChatCompletionCreateParamsWithModel<T extends z.AnyZodObject> = InstructorChatCompletionParams<T> & GenericCreateParams;
type ReturnTypeBasedOnParams<C, P> = P extends ({
    stream: true;
    response_model: ResponseModel<infer T>;
}) ? AsyncGenerator<Partial<z.infer<T>> & {
    _meta?: CompletionMeta;
}, void, unknown> : P extends {
    response_model: ResponseModel<infer T>;
} ? Promise<z.infer<T> & {
    _meta?: CompletionMeta;
}> : C extends OpenAI ? P extends {
    stream: true;
} ? Stream<OpenAI.Chat.Completions.ChatCompletionChunk> : OpenAI.Chat.Completions.ChatCompletion : Promise<unknown>;

declare const PROVIDERS: {
    readonly OAI: "OAI";
    readonly ANYSCALE: "ANYSCALE";
    readonly TOGETHER: "TOGETHER";
    readonly ANTHROPIC: "ANTHROPIC";
    readonly GROQ: "GROQ";
    readonly OTHER: "OTHER";
};
type Provider = keyof typeof PROVIDERS;

declare class Instructor<C> {
    readonly client: OpenAILikeClient<C>;
    readonly mode: Mode$1;
    readonly provider: Provider;
    readonly debug: boolean;
    readonly retryAllErrors: boolean;
    readonly logger?: <T extends unknown[]>(level: LogLevel, ...args: T) => void;
    /**
     * Creates an instance of the `Instructor` class.
     * @param {OpenAILikeClient} client - An OpenAI-like client.
     * @param {string} mode - The mode of operation.
     */
    constructor({ client, mode, debug, logger, retryAllErrors }: InstructorConfig<C>);
    private validateOptions;
    private validateModelModeSupport;
    private log;
    private chatCompletionStandard;
    private chatCompletionStream;
    private isChatCompletionCreateParamsWithModel;
    private isStandardStream;
    chat: {
        completions: {
            create: <T extends z.AnyZodObject, P extends T extends z.AnyZodObject ? ChatCompletionCreateParamsWithModel<T> : ClientTypeChatCompletionParams<OpenAILikeClient<C>> & {
                response_model: never;
            }>(params: P, requestOptions?: ClientTypeChatCompletionRequestOptions<C>) => Promise<ReturnTypeBasedOnParams<typeof this.client, P>>;
        };
    };
}
type InstructorClient<C> = Instructor<C> & OpenAILikeClient<C>;
/**
 * Creates an instance of the `Instructor` class.
 * @param {OpenAILikeClient} client - The OpenAI client.
 * @param {string} mode - The mode of operation.
 * @param {boolean} debug - Whether to log debug messages.
 * @returns {InstructorClient} The extended OpenAI client.
 *
 * @example
 * import createInstructor from "@instructor-ai/instructor"
 * import OpenAI from "openai
 *
 * const OAI = new OpenAi({})
 *
 * const client = createInstructor({
 *  client: OAI,
 *  mode: "TOOLS",
 * })
 *
 * @param args
 * @returns
 */
declare function createInstructor<C>(args: InstructorConfig<C>): InstructorClient<C>;

export { type ChatCompletionCreateParamsWithModel, type ClientType, type ClientTypeChatCompletionParams, type ClientTypeChatCompletionRequestOptions, type CompletionMeta, type GenericChatCompletion, type GenericChatCompletionStream, type GenericClient, type GenericCreateParams, type GenericRequestOptions, type InstructorChatCompletionParams, type InstructorClient, type InstructorConfig, type LogLevel, type Mode, type OpenAILikeClient, type ResponseModel, type ReturnTypeBasedOnParams, type SupportedInstructorClient, createInstructor as default };
